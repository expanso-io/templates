input:
  stdin:
    codec: lines

pipeline:
  processors:
    # Enrich with metadata
    - mapping: |
        root = this
        root.processed_at = now().ts_format("2006-01-02T15:04:05Z")
        root.partition_key = this.user_id catch "default"

# Fan-out to both outputs
output:
  broker:
    pattern: fan_out
    outputs:
      # Output 1: Archive to Blob Storage
      - azure_blob_storage:
          storage_account: "${AZURE_STORAGE_ACCOUNT}"
          storage_access_key: "${AZURE_STORAGE_ACCESS_KEY}"
          container: "${AZURE_CONTAINER}"
          path: "archive/${!timestamp_unix:2006}/${!timestamp_unix:01}/${!timestamp_unix:02}/${!this.event_id}.json"
          batching:
            count: 100
            period: "10s"

      # Output 2: Stream to Event Hubs
      - azure_event_hubs:
          connection_string: "${EVENTHUBS_CONNECTION_STRING}"
          eventhub: "${EVENTHUB_NAME}"
          partition_key: ${! json("partition_key") }
          batching:
            count: 100
            period: "10s"
